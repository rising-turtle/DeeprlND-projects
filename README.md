
# Projects from the DeepRL Nanodegree by Udacity

[//]: # (References)

<!-- IMAGES -->
[gif_project_1_banana_agent]: project1-navigation/imgs/gif_project_1_banana_agent.gif
[gif_project_1_lunarlander_agent]: project1-navigation/imgs/gif_project_1_lunarlander_agent.gif
[gif_project_2_reacher_multi_agent]: project2-continuous-control/imgs/gif_project_2_reacher_multi_agent.gif
[gif_project_3_tennis_agent]: project3-collaboration/imgs/gif_project_3_tennis_agent.gif

<!-- URLS -->
[url_project_1_code]: https://github.com/wpumacay/DeeprlND-projects/tree/master/project1-navigation
[url_project_1_post]: https://wpumacay.github.io/research_blog/posts/deeprlnd-project1-navigation/
[url_project_1_post_part_1]: https://wpumacay.github.io/research_blog/posts/deeprlnd-project1-part1/
[url_project_1_post_part_2]: https://wpumacay.github.io/research_blog/posts/deeprlnd-project1-part2/
[url_project_1_post_part_3]: https://wpumacay.github.io/research_blog/posts/deeprlnd-project1-part3/
[url_project_1_report]: https://github.com/wpumacay/DeeprlND-projects/blob/master/project1-navigation/REPORT.md

[url_project_2_code]: https://github.com/wpumacay/DeeprlND-projects/tree/master/project2-continuous-control
[url_project_2_report]: https://github.com/wpumacay/DeeprlND-projects/blob/master/project2-continuous-control/REPORT.md

[url_project_3_code]: https://github.com/wpumacay/DeeprlND-projects/tree/master/project3-collaboration
[url_project_3_report]: https://github.com/wpumacay/DeeprlND-projects/blob/master/project3-collaboration/REPORT.md

This repo contains implementations to the projects of the Deep Reinforcement Learning Nanodegree by Udacity. The projects
we have to implement as part of the course are the following:

- [x] **Simple navigation using DQN**: Implement a DQN-based agent to collect bananas in a virtual environment.
- [x] **Continuous control with DDPG and PPO**: Implement a (DDPG|PPO)-based agent to control its arm to reach a target location.
- [x] **Cooperation (Open ended project)**: Train two agents in a cooperative way to play tennis.

## [Project 1: DQN](https://github.com/wpumacay/DeeprlND-projects/tree/master/project1-navigation)

[CODE][url_project_1_code] | **POSTS**: [FULL][url_project_1_post] - [PART-1][url_project_1_post_part_1] - [PART-2][url_project_1_post_part_2] - [PART-3][url_project_1_post_part_3] | [REPORT][url_project_1_report]

![project-1-banana-agent][gif_project_1_banana_agent]

![project-1-lunarlander-agent][gif_project_1_lunarlander_agent]

## [Project 2: DDPG](https://github.com/wpumacay/DeeprlND-projects/tree/master/project2-continuous-control)

[CODE][url_project_2_code] | [REPORT][url_project_2_report]

![project-2-reacher-multi-agent][gif_project_2_reacher_multi_agent]

## [Project 3: MADDPG](https://github.com/wpumacay/DeeprlND-projects/tree/master/project3-collaboration)

[CODE][url_project_3_code] | [REPORT][url_project_3_report]

![project-3-tennis-agent][gif_project_3_tennis_agent]
